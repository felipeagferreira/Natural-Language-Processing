{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKmorPdno_n_"
   },
   "source": [
    "# Kiva Project \n",
    "\n",
    "Predict whether a Kiva loan application will default.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZFTCX4DqmRO"
   },
   "source": [
    "# Preliminaries: Inspect and Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LfOMt1lErLhZ",
    "outputId": "b8174afa-53e6-4423-9b5f-3b705b602152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aub2w1-arM5K",
    "outputId": "6009f6f5-a2c2-4e60-cbf1-c06ad67e04a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.10\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9Y_n_8UrO9i",
    "outputId": "98a93055-3879-4481-97b9-1157a66229d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/env/python\n"
     ]
    }
   ],
   "source": [
    "!echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUh4JyAIpagr",
    "outputId": "58b72ff3-b591-498a-d092-d91c5b8f5c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
      "Requirement already satisfied: textstat in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
      "Requirement already satisfied: pyphen in /usr/local/lib/python3.7/dist-packages (from textstat) (0.10.0)\n"
     ]
    }
   ],
   "source": [
    "pip install unidecode textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p24VrihfpgEr",
    "outputId": "0ffe8796-b4c7-4e8b-e1f4-a4f1c255e5c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 365,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 365,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "id": "AGs25flao_oJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "id": "Qrot1IOkqIxH"
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xj34Jz-Do_oK",
    "outputId": "63e15e01-de73-433c-cd90-35d2416fe34c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-09 22:36:19.389176\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hhS6imPgY92j",
    "outputId": "988fc56e-888f-429b-a43d-66a0a01957a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 369,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "id": "EugQT3oliaDn"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qj1NSQelo_oN"
   },
   "source": [
    "# Read Data\n",
    "\n",
    "We'll read the data from the links that Uncle Steve provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "id": "60UNWiX8YmLi"
   },
   "outputs": [],
   "source": [
    "# The labeled training data\n",
    "df = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1dzzVbgHphbCf7kvq9IKiIhwzmxPbuH4s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qeavkicwo_oN",
    "outputId": "c61ab625-19dd-4d86-a0f6-1fe259cc8c74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6138 entries, 0 to 6137\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   loan_id    6138 non-null   int64 \n",
      " 1   en_clean   6138 non-null   object\n",
      " 2   defaulted  6138 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 144.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7FIkMnao_oO"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "cgek8ghwo_oP",
    "outputId": "f8e0d5e9-cbb3-4d68-a347-1309789561f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>en_clean</th>\n",
       "      <th>defaulted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7779</td>\n",
       "      <td>She opened a colmado out of the side of her ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2777</td>\n",
       "      <td>(First Loan):  Joffre continues to run his loc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6007</td>\n",
       "      <td>Dina Santana is the mother of two children, Ju...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>Rosemary is 50 years old, single, and has 6 ch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4217</td>\n",
       "      <td>Segundo has a shop where he sells animal feed,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_id                                           en_clean  defaulted\n",
       "0     7779  She opened a colmado out of the side of her ho...          0\n",
       "1     2777  (First Loan):  Joffre continues to run his loc...          1\n",
       "2     6007  Dina Santana is the mother of two children, Ju...          0\n",
       "3       76  Rosemary is 50 years old, single, and has 6 ch...          1\n",
       "4     4217  Segundo has a shop where he sells animal feed,...          0"
      ]
     },
     "execution_count": 449,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rMtMpjHSGbMz",
    "outputId": "0fd2d957-59e6-4dda-e117-23294f58f5c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3102\n",
       "1    3036\n",
       "Name: defaulted, dtype: int64"
      ]
     },
     "execution_count": 450,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['defaulted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3HbKKatgmxa",
    "outputId": "eaa5a5fd-81bf-4b24-fdf0-60d0b5b2ceed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6129, 3)"
      ]
     },
     "execution_count": 451,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates('en_clean')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "id": "a0scBscjo_oQ"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "id": "ez0AoK6-o_oQ",
    "outputId": "6e9488b6-1c3c-4827-b9f7-1117ca97ed28"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Antonio\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " has a spot at a local market where he sells jewelry, laces and other items. He buys the merchandise in whole sale packages from a local distributor. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Antonio\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " has been watching his parents in this type of activity from a very young age. They owned a stand at a local market where \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Antonio\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " would always visit and help out. Eventually, his father provided him with $\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    50\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " worth of merchandise in order to get \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Antonio\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " started in his own business. He sells all his products for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $1 or\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " less because he works in very poor communities where people cannot afford to pay more. Antonio is seeking the loan so he may purchase at larger quantities from wholesalers. He is hoping to invest in new and different products that are still affordable to his clients. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Antonio\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is only \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    22 years old\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". He is currently a student at a local college. His business helped him cover the expense from finishing high school and attending college. He hopes to continue running his business until he graduates when he wants to open a much a larger operation.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can use spacy to show all the named entities in a given document.\n",
    "\n",
    "doc = nlp(df.iloc[4001].en_clean)\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "er6haRkwGMQi"
   },
   "source": [
    "Add Text Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Whkw6JTTGKyU",
    "outputId": "846cdca5-4175-411e-f809-6dee0625ad1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 454,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install textaugment\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from textaugment import Wordnet\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "id": "D378WfurGS_h"
   },
   "outputs": [],
   "source": [
    "def augment_text(df,samples=1000):\n",
    "    t = Wordnet()\n",
    "    new_text_majority=[]\n",
    "    \n",
    "    ##selecting the majority class samples\n",
    "    df_n=df[df.defaulted==1].reset_index(drop=True)\n",
    "\n",
    "    ## data augmentation loop\n",
    "    for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
    "        \n",
    "            text = df_n.iloc[i]['en_clean']\n",
    "            augmented_text = t.augment(text)\n",
    "            new_text_majority.append(augmented_text)\n",
    "    \n",
    "    ## dataframe\n",
    "    new=pd.DataFrame({'en_clean':new_text_majority,'defaulted':1})\n",
    "    df=shuffle(df.append(new).reset_index(drop=True))\n",
    "\n",
    "\n",
    "    new_text_minority=[]\n",
    "\n",
    "    ##selecting the minority class samples\n",
    "    df_n=df[df.defaulted==0].reset_index(drop=True)\n",
    "\n",
    "    ## data augmentation loop\n",
    "    for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
    "        \n",
    "            text = df_n.iloc[i]['en_clean']\n",
    "            augmented_text = t.augment(text)\n",
    "            new_text_minority.append(augmented_text)\n",
    "    \n",
    "\n",
    "    ## dataframe\n",
    "    new=pd.DataFrame({'en_clean':new_text_minority,'defaulted':0})\n",
    "    df=shuffle(df.append(new).reset_index(drop=True))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZCzW8hFGXwX",
    "outputId": "1a43243f-ff38-479e-bd3c-5e4ac389ff3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:08<00:00, 115.37it/s]\n",
      "100%|██████████| 1000/1000 [00:07<00:00, 125.95it/s]\n"
     ]
    }
   ],
   "source": [
    "df = augment_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46Z1hbP6GkRv",
    "outputId": "b2c5bb1c-268f-4968-bac0-ad4b40170dc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4096\n",
       "1    4033\n",
       "Name: defaulted, dtype: int64"
      ]
     },
     "execution_count": 457,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['defaulted'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6I9xt79wqtFu"
   },
   "source": [
    "Add Sentiment Label Score Feature using Vander package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gaiLOr8PqsRf",
    "outputId": "4c4875e0-67fa-483e-d16a-86d8768a1813"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 458,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jg1liDNnrFFu",
    "outputId": "fa544fe1-8106-491e-baa8-f83d4e1caf33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.4404, 'neg': 0.0, 'neu': 0.508, 'pos': 0.492}"
      ]
     },
     "execution_count": 459,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'This was a good movie.'\n",
    "sid.polarity_scores(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "id": "5_tR43zvrQKd"
   },
   "outputs": [],
   "source": [
    "df['scores'] = df['en_clean'].apply(lambda review: sid.polarity_scores(review))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "9xBgAKpPsA0Q",
    "outputId": "15e04412-4ecd-4bc2-884f-993b9c3ddf98"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>en_clean</th>\n",
       "      <th>defaulted</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>comp_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>6376.0</td>\n",
       "      <td>Ramona is 45 years old and has 10 children and...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.95, 'pos': 0.05, 'compou...</td>\n",
       "      <td>0.5927</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7578</th>\n",
       "      <td>NaN</td>\n",
       "      <td>this group, as a part of a larger, successful ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.892, 'pos': 0.108, 'comp...</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5092</th>\n",
       "      <td>1534.0</td>\n",
       "      <td>Beatrice Anne Wangu is a single mother of 2 ch...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.02, 'neu': 0.842, 'pos': 0.139, 'com...</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2854</th>\n",
       "      <td>7537.0</td>\n",
       "      <td>In the words of Luchi Aquino, the group has do...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.017, 'neu': 0.846, 'pos': 0.136, 'co...</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>1088.0</td>\n",
       "      <td>I am a married man, a father of 3. I sell cook...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.839, 'pos': 0.161, 'comp...</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>46.0</td>\n",
       "      <td>Catherine is 49 years old. She is a single lad...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.916, 'pos': 0.084, 'comp...</td>\n",
       "      <td>0.9245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>NaN</td>\n",
       "      <td>grace waiyego is a member of the easter mother...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.928, 'pos': 0.072, 'comp...</td>\n",
       "      <td>0.8316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>NaN</td>\n",
       "      <td>naomi wanjiku kimotho live born 40 years ago i...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7244</th>\n",
       "      <td>NaN</td>\n",
       "      <td>virginia is an active member of kabuta ladies ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.917, 'pos': 0.083, 'comp...</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>766.0</td>\n",
       "      <td>She is married with 3 children where all of th...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>7439.0</td>\n",
       "      <td>Martha Oyando is a 36-year-old woman living in...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.013, 'neu': 0.905, 'pos': 0.082, 'co...</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7228</th>\n",
       "      <td>NaN</td>\n",
       "      <td>edeisi, who was deport in esmeralda, ecuador, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.036, 'neu': 0.939, 'pos': 0.025, 'co...</td>\n",
       "      <td>-0.1779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>3380.0</td>\n",
       "      <td>Lucia is the leader of this group of women who...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.077, 'neu': 0.857, 'pos': 0.066, 'co...</td>\n",
       "      <td>-0.2484</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7179.0</td>\n",
       "      <td>Mara Herminia sells costume jewelry and beauty...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.008, 'neu': 0.725, 'pos': 0.267, 'co...</td>\n",
       "      <td>0.9891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8099</th>\n",
       "      <td>NaN</td>\n",
       "      <td>mr. lihanda is espouse with three children. hi...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.036, 'neu': 0.811, 'pos': 0.153, 'co...</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>NaN</td>\n",
       "      <td>for 13 years, maria take been selling fried po...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.006, 'neu': 0.876, 'pos': 0.118, 'co...</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>5193.0</td>\n",
       "      <td>Carmita has 2 years of experience with this bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.007, 'neu': 0.918, 'pos': 0.075, 'co...</td>\n",
       "      <td>0.9313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4637</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ruth is 33 years old, marry and own 3 children...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.007, 'neu': 0.923, 'pos': 0.07, 'com...</td>\n",
       "      <td>0.9112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Sarah is 27 years of age and married. She is a...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.012, 'neu': 0.966, 'pos': 0.022, 'co...</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356</th>\n",
       "      <td>1776.0</td>\n",
       "      <td>William Awande Were is aged 37 years. He is ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.021, 'neu': 0.905, 'pos': 0.073, 'co...</td>\n",
       "      <td>0.8442</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loan_id  ... comp_score\n",
       "465    6376.0  ...          1\n",
       "7578      NaN  ...          1\n",
       "5092   1534.0  ...          1\n",
       "2854   7537.0  ...          1\n",
       "4625   1088.0  ...          1\n",
       "4306     46.0  ...          1\n",
       "3716      NaN  ...          1\n",
       "3623      NaN  ...          1\n",
       "7244      NaN  ...          1\n",
       "1265    766.0  ...          1\n",
       "4042   7439.0  ...          1\n",
       "7228      NaN  ...          0\n",
       "1088   3380.0  ...          0\n",
       "122    7179.0  ...          1\n",
       "8099      NaN  ...          1\n",
       "562       NaN  ...          1\n",
       "6995   5193.0  ...          1\n",
       "4637      NaN  ...          1\n",
       "936       8.0  ...          1\n",
       "3356   1776.0  ...          1\n",
       "\n",
       "[20 rows x 6 columns]"
      ]
     },
     "execution_count": 461,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['compound']  = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "df['comp_score'] = df['compound'].apply(lambda c: 1 if c >=0 else 0)\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "id": "slgZa74MVFxB"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from functools import partial\n",
    "def spacy_tokenize(text, nlp):\n",
    "    return [x.orth_ for x in nlp(text)]\n",
    "\n",
    "nlp = spacy.load('en', disable=['ner', 'parser', 'tagger'])\n",
    "tok = partial(spacy_tokenize, nlp=nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "id": "kKZP5uJ0dboP"
   },
   "outputs": [],
   "source": [
    "#funtion to get 'top N' or 'bottom N' words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "def get_n_words(corpus, direction, n):\n",
    "    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    if direction == \"top\":\n",
    "        words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    else:\n",
    "        words_freq =sorted(words_freq, key = lambda x: x[1], reverse=False)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "id": "QQi4GTYedns9"
   },
   "outputs": [],
   "source": [
    "#10 most common and 10 most rare words\n",
    "common_words = get_n_words(df['en_clean'], \"top\", 15)\n",
    "rare_words = get_n_words(df['en_clean'], \"bottom\", 500)\n",
    "#common_words, rare_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Pku10w2d2Ng",
    "outputId": "ff23b12e-3e34-440f-e74c-5b47ff1e4f90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 s, sys: 40.4 ms, total: 12.8 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "#Removing common and rare words\n",
    "#%time df['en_clean'] = df['en_clean'].map(lambda x : ' '.join([w for w in x.split() if w not in common_words]))\n",
    "%time df['en_clean'] = df['en_clean'].map(lambda x : ' '.join([w for w in x.split() if w not in rare_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "oUcVq6R1usfd",
    "outputId": "520e8418-f589-413d-d012-4bfc138e1936"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>en_clean</th>\n",
       "      <th>defaulted</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>comp_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>6376.0</td>\n",
       "      <td>Ramona is 45 years old and has 10 children and...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.95, 'pos': 0.05, 'compou...</td>\n",
       "      <td>0.5927</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7578</th>\n",
       "      <td>NaN</td>\n",
       "      <td>this group, as a part of a larger, successful ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.892, 'pos': 0.108, 'comp...</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5092</th>\n",
       "      <td>1534.0</td>\n",
       "      <td>Beatrice Anne Wangu is a single mother of 2 ch...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.02, 'neu': 0.842, 'pos': 0.139, 'com...</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2854</th>\n",
       "      <td>7537.0</td>\n",
       "      <td>In the words of Luchi Aquino, the group has do...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.017, 'neu': 0.846, 'pos': 0.136, 'co...</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>1088.0</td>\n",
       "      <td>I am a married man, a father of 3. I sell cook...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.839, 'pos': 0.161, 'comp...</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>46.0</td>\n",
       "      <td>Catherine is 49 years old. She is a single lad...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.916, 'pos': 0.084, 'comp...</td>\n",
       "      <td>0.9245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>NaN</td>\n",
       "      <td>grace waiyego is a member of the easter mother...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.928, 'pos': 0.072, 'comp...</td>\n",
       "      <td>0.8316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>NaN</td>\n",
       "      <td>naomi wanjiku kimotho live born 40 years ago i...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7244</th>\n",
       "      <td>NaN</td>\n",
       "      <td>virginia is an active member of kabuta ladies ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.917, 'pos': 0.083, 'comp...</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>766.0</td>\n",
       "      <td>She is married with 3 children where all of th...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loan_id  ... comp_score\n",
       "465    6376.0  ...          1\n",
       "7578      NaN  ...          1\n",
       "5092   1534.0  ...          1\n",
       "2854   7537.0  ...          1\n",
       "4625   1088.0  ...          1\n",
       "4306     46.0  ...          1\n",
       "3716      NaN  ...          1\n",
       "3623      NaN  ...          1\n",
       "7244      NaN  ...          1\n",
       "1265    766.0  ...          1\n",
       "\n",
       "[10 rows x 6 columns]"
      ]
     },
     "execution_count": 466,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjUgRW1N6ppS"
   },
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "id": "ksKqf_fV6pIO"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "\n",
    "X = df['en_clean']\n",
    "y = df['defaulted']\n",
    "\n",
    "# So that we can evaluate how well our model is performing, we split our training data\n",
    "# into training and validation.\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m8acyCrZt3sO",
    "outputId": "558485b9-3081-436b-b5fb-4bc5bad858fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465     Ramona is 45 years old and has 10 children and...\n",
       "7578    this group, as a part of a larger, successful ...\n",
       "5092    Beatrice Anne Wangu is a single mother of 2 ch...\n",
       "2854    In the words of Luchi Aquino, the group has do...\n",
       "4625    I am a married man, a father of 3. I sell cook...\n",
       "                              ...                        \n",
       "2766    Henry Gachigua Muturi is 60 years and has seve...\n",
       "41      ruth is a good member of kahumbu kwirera mothe...\n",
       "8065    sandra is a straightforward and humble woman w...\n",
       "7401    margaret be marry with five children all in pr...\n",
       "233     Dominga is a hard working woman who started he...\n",
       "Name: en_clean, Length: 8129, dtype: object"
      ]
     },
     "execution_count": 468,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "598AtzLCo_oV"
   },
   "source": [
    "# Feature Engineering and Extraction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "id": "y4D4cu49o_oS"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import unidecode\n",
    "\n",
    "# A nice preprocessing function that we can pass to CountVectorizer/TfidfVectorizer\n",
    "def my_preprocess(doc):\n",
    "\n",
    "    # Lowercase everything\n",
    "    res = doc.lower()\n",
    "    \n",
    "    # Remove any \"weird\" characters\n",
    "    res = unidecode.unidecode(res)\n",
    "\n",
    "    #print(res)\n",
    "\n",
    "    # TODO: What else?\n",
    "    SYM_REPLACE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    REM_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "    res = SYM_REPLACE.sub(' ', res) \n",
    "    res = REM_SYMBOLS_RE.sub('', res) \n",
    "\n",
    "    # Create Lemmatizer object\n",
    "    wnl = WordNetLemmatizer()\n",
    "    list2 = nltk.word_tokenize(res)\n",
    "    res = ' '.join([wnl.lemmatize(words) for words in list2])\n",
    "\n",
    "    # Remove stopwords\n",
    "    all_stopwords = nlp.Defaults.stop_words\n",
    "    text_tokens = word_tokenize(res)\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
    "    res = (\" \").join(tokens_without_sw)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "id": "TOad40BVj5gU"
   },
   "outputs": [],
   "source": [
    "# These functions will calculate additional features on the document.\n",
    "# They will be put into the Pipeline, called via the FunctionTransformer() function.\n",
    "# Each one takes an entire corpus (as a list of documents), and should return\n",
    "# an array of feature values (one for each document in the corpus).\n",
    "# These functions can do anything they want; I've made most of them quick\n",
    "# one-liners Hopefully the names of the functions will make them self explanitory.\n",
    "\n",
    "def doc_length(corpus):\n",
    "    #print(corpus)\n",
    "    return np.array([len(doc) for doc in corpus]).reshape(-1, 1)\n",
    "\n",
    "def num_exclamation_marks(corpus):\n",
    "    return np.array([doc.count('!') for doc in corpus]).reshape(-1, 1)\n",
    "\n",
    "def count_loan(corpus):\n",
    "    return np.array([doc.count('loan') for doc in corpus]).reshape(-1, 1)\n",
    "\n",
    "def generate_sentiment_score(corpus):\n",
    "  score_dict = [sid.polarity_scores(doc) for doc in corpus]\n",
    "  score = []\n",
    "  for key in score_dict:\n",
    "    #print(key['compound'])\n",
    "    score.append(key['compound'])\n",
    "\n",
    "    # if key['compound'] >= 0:\n",
    "    #   score.append(1)\n",
    "    # else:\n",
    "    #   score.append(1)\n",
    "  return np.array(score).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "id": "AjQQB8FRkFm-"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#0.86 - F1 macro using random forest\n",
    "vectorizer = CountVectorizer(preprocessor=my_preprocess,  tokenizer=tok,min_df=2, \n",
    "                             max_df=0.5, max_features=1000,\n",
    "                             stop_words='english', ngram_range=(1, 2))\n",
    "# vectorizer = CountVectorizer(preprocessor=my_preprocess, min_df=2, \n",
    "#                              max_df=0.5, max_features=1000,\n",
    "#                              ngram_range=(1, 2))\n",
    "# This vectorizer will be used to create the BOW features.\n",
    "# vectorizer = TfidfVectorizer(preprocessor=my_preprocess, \n",
    "#                              tokenizer=tok,\n",
    "#                              max_features = 1000, \n",
    "#                              use_idf=True,\n",
    "#                              stop_words='english',\n",
    "#                              min_df=2, max_df=10, ngram_range=[1,2])\n",
    "\n",
    "rf = RandomForestClassifier(criterion='entropy', random_state=1)\n",
    "\n",
    "# We will \"union\" together the BOW features and the custom-created features we\n",
    "# created in the cell above.\n",
    "feature_processing =  FeatureUnion([ \n",
    "    ('bow', Pipeline([('vectorizer', vectorizer), ])),\n",
    "    ('doc_length', FunctionTransformer(doc_length, validate=False)),\n",
    "    ('num_exclamation_marks', FunctionTransformer(num_exclamation_marks, validate=False)),\n",
    "    ('sentiment_score', FunctionTransformer(generate_sentiment_score, validate=False)),  \n",
    "   # ('count_loan', FunctionTransformer(count_loan, validate=False)),  \n",
    "])\n",
    "\n",
    "pipe = Pipeline([('features', feature_processing), ('clf', rf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isb2-cFWJ5lX"
   },
   "source": [
    "# Model Training/Tuning/Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thGaEG4dkv2t",
    "outputId": "67a8b9fb-a314-4c0a-bdf3-bbe8e131ae66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=5)]: Done  80 out of  80 | elapsed: 15.6min finished\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ca', 'ha', 'le', 'nt', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# The names of the hypter parameters may look a bit funny; it's based on how they\n",
    "# are added to the Pipeline object above (and seperated with double underscores)\n",
    "# param_grid = {\n",
    "#     'features__bow__vectorizer__max_features': [1000,1200, 1300, 1500],\n",
    "#     'features__bow__vectorizer__use_idf': [True, False],\n",
    "#     'clf__n_estimators': [10, 100,200],\n",
    "#     'features__doc_length' : [True, False],\n",
    "#     'features__num_exclamation_marks' : [True, False],\n",
    "#     'features__sentiment_score' : [True, False],\n",
    "\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'features__bow__vectorizer__max_features': [1000,1150,1200, 1300],\n",
    "    'clf__n_estimators': [100,200,250,300],\n",
    "    'features__bow__vectorizer__ngram_range': [(1, 2)],\n",
    "}\n",
    "\n",
    "\n",
    "#cv = StratifiedKFold(n_splits=8)\n",
    "search = GridSearchCV(pipe, \n",
    "                      param_grid, \n",
    "                      cv=5, \n",
    "                      n_jobs=5, \n",
    "                      scoring='f1_macro', \n",
    "                      return_train_score=True, \n",
    "                      verbose=2)\n",
    "\n",
    "search = search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "haxVEq0chNc_",
    "outputId": "9ab84eb7-6cf3-4969-a3e6-c7e88fa9c434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score: 0.89729):\n",
      "{'clf__n_estimators': 200, 'features__bow__vectorizer__max_features': 1150, 'features__bow__vectorizer__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter (CV score: %0.5f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zo1ErxuDiDzD",
    "outputId": "005617f0-ba9d-4ae0-e82d-a18a87e61592"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 10 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=5)]: Done  62 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=5)]: Done  80 out of  80 | elapsed: 15.8min finished\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ca', 'ha', 'le', 'nt', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# param_grid = {\n",
    "#     'features__bow__vectorizer__max_features': [500, 1000,1200,1500,2000],\n",
    "#     'features__bow__vectorizer__use_idf': [True, False],\n",
    "#     'clf__n_estimators': [100,200],\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'features__bow__vectorizer__max_features': [1000,1150,1200, 1300],\n",
    "    'clf__n_estimators': [100,200,250],\n",
    "    'features__bow__vectorizer__ngram_range': [(1, 2)],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=8)\n",
    "search = RandomizedSearchCV(pipe, param_distributions=param_grid, cv=cv, n_jobs=5,  scoring='f1_macro', return_train_score=True, verbose=8)\n",
    "search = search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H-8l7TMUwP3a",
    "outputId": "42d4ef06-0956-4b3b-d028-90b784c9b737"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score: 0.89713):\n",
      "{'features__bow__vectorizer__ngram_range': (1, 2), 'features__bow__vectorizer__max_features': 1200, 'clf__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter (CV score: %0.5f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_VcUjHulQ9p"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "sa5zY1t8lQvK",
    "outputId": "968f4a89-c29a-4206-f5cb-c384efddb340"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features__bow__vectorizer__ngram_range</th>\n",
       "      <th>features__bow__vectorizer__max_features</th>\n",
       "      <th>clf__n_estimators</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1200</td>\n",
       "      <td>200</td>\n",
       "      <td>30.117843</td>\n",
       "      <td>2.863831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.897131</td>\n",
       "      <td>0.009141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1200</td>\n",
       "      <td>250</td>\n",
       "      <td>32.459792</td>\n",
       "      <td>2.891084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896141</td>\n",
       "      <td>0.010902</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1150</td>\n",
       "      <td>250</td>\n",
       "      <td>32.418310</td>\n",
       "      <td>2.893218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.895312</td>\n",
       "      <td>0.011882</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1000</td>\n",
       "      <td>250</td>\n",
       "      <td>33.036060</td>\n",
       "      <td>2.896794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.894667</td>\n",
       "      <td>0.009284</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1300</td>\n",
       "      <td>200</td>\n",
       "      <td>30.495811</td>\n",
       "      <td>2.893356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.894504</td>\n",
       "      <td>0.011710</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1300</td>\n",
       "      <td>100</td>\n",
       "      <td>25.811119</td>\n",
       "      <td>2.855398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.894004</td>\n",
       "      <td>0.010988</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1150</td>\n",
       "      <td>200</td>\n",
       "      <td>30.379202</td>\n",
       "      <td>2.883795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893510</td>\n",
       "      <td>0.011910</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1150</td>\n",
       "      <td>100</td>\n",
       "      <td>26.272253</td>\n",
       "      <td>2.852501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.892524</td>\n",
       "      <td>0.010039</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>26.091417</td>\n",
       "      <td>2.843392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.889568</td>\n",
       "      <td>0.009970</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1200</td>\n",
       "      <td>100</td>\n",
       "      <td>26.139821</td>\n",
       "      <td>2.851814</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.889404</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  features__bow__vectorizer__ngram_range  ...  rank_test_score\n",
       "4                                 (1, 2)  ...                1\n",
       "8                                 (1, 2)  ...                2\n",
       "3                                 (1, 2)  ...                3\n",
       "0                                 (1, 2)  ...                4\n",
       "2                                 (1, 2)  ...                5\n",
       "9                                 (1, 2)  ...                6\n",
       "7                                 (1, 2)  ...                7\n",
       "1                                 (1, 2)  ...                8\n",
       "5                                 (1, 2)  ...                9\n",
       "6                                 (1, 2)  ...               10\n",
       "\n",
       "[10 rows x 10 columns]"
      ]
     },
     "execution_count": 476,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the results of hyperparmater tuning\n",
    "\n",
    "def cv_results_to_df(cv_results):\n",
    "    results = pd.DataFrame(list(cv_results['params']))\n",
    "    results['mean_fit_time'] = cv_results['mean_fit_time']\n",
    "    results['mean_score_time'] = cv_results['mean_score_time']\n",
    "    results['mean_train_score'] = cv_results['mean_train_score']\n",
    "    results['std_train_score'] = cv_results['std_train_score']\n",
    "    results['mean_test_score'] = cv_results['mean_test_score']\n",
    "    results['std_test_score'] = cv_results['std_test_score']\n",
    "    results['rank_test_score'] = cv_results['rank_test_score']\n",
    "\n",
    "    results = results.sort_values(['mean_test_score'], ascending=False)\n",
    "    return results\n",
    "\n",
    "results = cv_results_to_df(search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1Oxr9djo_oa"
   },
   "source": [
    "# Model Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "id": "6NY_yGyRo_oa"
   },
   "outputs": [],
   "source": [
    "y_val_pred = search.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QjIY8DDto_ob",
    "outputId": "c7706bb0-ebb3-4323-a08d-ab246fdb8c18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[966  84]\n",
      " [122 861]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90      1050\n",
      "           1       0.91      0.88      0.89       983\n",
      "\n",
      "    accuracy                           0.90      2033\n",
      "   macro avg       0.90      0.90      0.90      2033\n",
      "weighted avg       0.90      0.90      0.90      2033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(confusion_matrix(y_true = y_val, y_pred = y_val_pred))\n",
    "\n",
    "class_names = [str(x) for x in search.best_estimator_.classes_]\n",
    "print(classification_report(y_true = y_val, y_pred = y_val_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxWpS_pSK6El"
   },
   "source": [
    "# Kaggle Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "id": "GX_6pu4OK46Y"
   },
   "outputs": [],
   "source": [
    "# Read in the unlabeled testing data (for the Kaggle competition)\n",
    "df_test = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1EVWfyqQOd_W2uTKrr4JTD2iFrEZHoOHT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "OUqg7Lp-Lqy2",
    "outputId": "aa0fdb2d-bb22-4566-a8b4-3d05c2e60aa6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6607</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2617</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  predicted\n",
       "0  6607          0\n",
       "1   154          1\n",
       "2  7402          0\n",
       "3  2617          1\n",
       "4  6464          0"
      ]
     },
     "execution_count": 488,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use our pipeline to make predictions; then output predictions to a CSV file.\n",
    "\n",
    "pred_test = search.predict(df_test['en_clean'])\n",
    "my_submission = pd.DataFrame({'id': df_test['loan_id'], 'predicted': pred_test})\n",
    "my_submission.head()\n",
    "\n",
    "# This command will save the file to the local cloud instance; it will be deleted\n",
    "# as soon as this Notebooks session ends.\n",
    "my_submission.to_csv('my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "RKtdKCTYUwGq",
    "outputId": "f3f34901-33a4-4755-ad63-5ba1eb421e6a"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_e86c1b3c-db58-48b9-a557-965eec4bfaf0\", \"my_submission.csv\", 4552)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download predictions file to your local computer\n",
    "\n",
    "from google.colab import files\n",
    "files.download('my_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y7F5ZgWwxnD2",
    "outputId": "a43dcbd3-6197-41d5-971a-73af8921a1a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-10 00:04:26.910694\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4VUmXRIGbtF"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "MMAI_2021_891_Final_Project_Team_Union_0328v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
